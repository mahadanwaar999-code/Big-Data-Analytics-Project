Inventory Management (historic sales data) system that computes upper & lower stock bounds (safety stock, reorder points, min/max levels) with no AI models. This plan uses a MERN frontend, MongoDB as the primary store, Python for backend data manipulation/ETL/statistics, and Docker for containerization. I give architecture, data model, algorithms (statistical/time-series non-AI), API design, frontend features, deployment, monitoring, testing, and a suggested milestone timeline.

1 — High-level architecture (textual)

Clients (browser/mobile) ←→ MERN frontend (React)
React ↔ Express (Node.js) API server — auth, CRUD for products/orders/customers, UI-specific endpoints
Python data-processing service (FastAPI or Flask) — ETL, historical aggregations, compute stock bounds, scheduled jobs
MongoDB — operational collections (sales, products, inventory, suppliers, orders, events)
Long-term analytics / cold storage — optionally Parquet files on object storage (MinIO / S3) or a separate analytics DB if dataset grows huge
Redis — caching and job queue (optional)
Docker Compose / Kubernetes for orchestration
Monitoring: Prometheus + Grafana or simpler (host metrics + logs)

2 — High-level data flow

Sales transactions created by POS / frontend → written to MongoDB sales collection.

Change stream or scheduled ETL extracts daily/weekly batches to analytics store.

Python ETL aggregates historical sales per SKU/time-window, computes demand distribution, lead time, reorder point, safety stock, EOQ if needed.

Computed bounds stored in inventory_bounds collection; frontend queries those to show min/max, reorder suggestions, alerts.

Alerts trigger email/SMS or dashboard notifications when stock < reorder point or > upper bound.

3 — Key concepts & formulas (non-AI/statistical)

You’ll use classical inventory formulas and statistics:

Average demand (D̄) — e.g., daily/weekly avg over past N periods.
D̄ = (sum of demand over N periods) / N.

Std. deviation of demand (σd) — compute daily/weekly demand stddev.

Lead time (L) — time (days) supplier takes to deliver after reorder. Can compute mean lead time from historical purchase orders.

Reorder Point (ROP) = D̄ × L + SafetyStock.

Safety stock (service-level approach):
SafetyStock = z × σLT
where σLT = √(L) × σd under simple iid demand assumption (if demand variance independent of lead time) — or more generally σLT = √(L×σd² + D̄²×σL²) if lead-time varies.
z is the standard normal z-score for desired service level (e.g., z≈1.645 for 95% service level).

Min / Max bounds:

Min stock = ROP (or ROP − reorder quantity tolerance)

Max stock = ROP + OrderQuantity (or use safety buffer + EOQ)

EOQ (Economic Order Quantity) (optional):
EOQ = sqrt( (2 × D × S) / H )
where D = annual demand, S = ordering cost per order, H = holding cost per unit per year.

Moving average / Exponential smoothing for trend/seasonality (non-AI). Use simple moving average for short-term smoothing; Holt-Winters for seasonality if needed.

Croston’s method for intermittent demand (non-AI statistical method).

These are standard, well-understood formulas and do not rely on machine learning.

4 — Database design (MongoDB) — collections & sample documents

Use MongoDB for operational data. Keep historical sales in collections partitioned by time if huge. Add indexes for aggregation performance.

Collections:

products

{
  "_id":"SKU1234",
  "name":"Widget A",
  "category":"Widgets",
  "unit":"pcs",
  "lead_time_days":7,
  "reorder_cost": 30.0,
  "holding_cost_per_unit_per_year": 2.5,
  "min_order_qty": 10,
  "supplier_id": "SUP1",
  "created_at": ISODate(...)
}


sales (append-only, time-series style)

{
  "_id": ObjectId(...),
  "sku":"SKU1234",
  "order_id":"SO-2025-0001",
  "quantity": 5,
  "sale_date": ISODate("2025-09-01T10:15:00Z"),
  "store_id":"STORE1",
  "channel":"online"
}


Index on { sku:1, sale_date:1 } and maybe a time-series collection for huge volumes.

inventory (current snapshot per SKU per location)

{
  "_id":"INV-SKU1234-LOC1",
  "sku":"SKU1234",
  "location":"LOC1",
  "on_hand": 120,
  "reserved": 10,
  "available": 110,
  "last_counted": ISODate(...),
  "last_updated": ISODate(...)
}


purchase_orders (incoming PO, used to compute lead-time history)

{
  "_id":"PO-0001",
  "sku":"SKU1234",
  "qty":100,
  "ordered_date": ISODate(...),
  "received_date": ISODate(...),
  "supplier_id":"SUP1"
}


inventory_bounds (computed by Python jobs)

{
  "sku":"SKU1234",
  "location":"LOC1",
  "computed_at": ISODate(...),
  "avg_daily_demand": 6.2,
  "stddev_daily_demand": 2.1,
  "lead_time_days": 7,
  "safety_stock": 8,
  "reorder_point": 6.2*7 + 8,
  "min_level": 51,
  "max_level": 151,
  "recommended_order_qty": 100,
  "method":"rolling_90d_moving_avg",
  "notes":"Seasonal adjustments applied"
}


events / alerts — user notifications when a SKU breaches bounds.

5 — Indexing & scaling tips in MongoDB

Index sales on {sku:1, sale_date:1} for time-series aggregations.

For large volumes, use MongoDB time-series collections (designed for append-only time-based data).

Consider sharding on sku or store_id when dataset grows very large.

Keep frequently-read small collections (inventory, inventory_bounds) on replica set secondaries for read scaling.

Keep ETL-friendly timestamps and partitioning fields.

6 — Backend design: responsibilities & components

Two backend components:

A. Node/Express API (MERN typical):

Auth routes (JWT)

CRUD for products, inventory, suppliers, users, stores

UI endpoints (dashboard queries) — aggregate summaries, top stockouts, alerts

Proxy requests to Python data-service for recalculation triggers

B. Python Data Service (FastAPI recommended):

ETL pipelines: batch jobs to aggregate historic sales into demand time series.

Statistical computations: average, stddev, lead time estimation, safety stock, reorder point, EOQ, moving averages, exponential smoothing (single & Holt-Winters), Croston for intermittent demand.

Expose endpoints: POST /compute-bounds/sku, POST /compute-bounds/batch, GET /bounds/sku etc.

Scheduler integration: run daily/weekly recalculations. Use cron (Linux cron), APScheduler, or Celery beat for scheduling. Use Redis + RQ/Celery for job queue if heavy.

Write results to inventory_bounds collection.

C. ETL Steps in Python (detailed)

Extract: query sales for SKU and date range (e.g., last 365 days).

Transform: roll up to daily demand series per SKU→location. Deal with missing days (fill zeros).

Analyze:

compute D̄, σd over chosen window (rolling windows e.g., 30/90/365 days).

check for seasonality (autocorrelation) — if seasonal, use Holt-Winters for forecasting demand.

compute empirical lead-time distribution from purchase_orders history.

determine service-level (configurable per SKU/class). Convert to z-score.

compute safety stock & reorder point.

compute recommended order qty (EOQ or multiple of pack/min_order_qty).

Load: write or update inventory_bounds. Emit alerts if current inventory.available <= reorder_point.

Logging & metrics.

7 — Algorithms & implementation notes (no AI)

Rolling windows: compute demand metrics using rolling window (30/90/365 days) and maintain both short-term and long-term metrics.

Seasonal smoothing: use Holt-Winters additive or multiplicative if seasonal. Implementation available in statsmodels (but that’s not ML). If you want to avoid external heavy libs, implement simple ETS yourself or use pandas moving averages + seasonal indices.

Intermittent demand: use Croston's method when many zero-demand days (sales spikes occasionally).

Outlier handling: winsorize or cap extreme demand spikes (e.g., > 3σ) before computing averages, or track as special events.

Parameter configuration: per SKU or per category thresholds (service level, window lengths, min_order_qty). Use product collection fields for overrides.

Validation: backtest computed bounds against historical stockouts — simulate using historic data and compute service level achieved.

8 — API design (examples)

Node/Express (authentication via JWT):

GET /api/products

GET /api/products/:sku

POST /api/inventory/adjust

GET /api/inventory/:sku

GET /api/bounds/:sku — returns latest computed bounds (from inventory_bounds)

POST /api/bounds/compute — triggers recompute for given SKUs (proxy to Python service)

Python FastAPI:

POST /compute-bounds — body: {"skus":["SKU1","SKU2"], "window_days":90, "service_level":0.95}

GET /bounds/sku/{sku} — returns computed bounds JSON

GET /health — basic health check

9 — Frontend (MERN) — required pages & components

Focus: dashboards, SKU pages, alerts, manual overrides, reports.

Core features:

Authentication & role-based access (admin, inventory_clerk, viewer)

Dashboard: summary KPIs (stockouts last 30d, reorder suggestions, value of stock, ageing)

Product list with current inventory, min/max, recommended action

SKU detail page: demand chart (daily/weekly), seasonality, last 365 days, computed bounds, reorder history, PO history

Bulk actions: bulk reorder, bulk recompute bounds for selected SKUs

Alerts/Notifications page: low-stock, overstock, late PO deliveries

Settings: service-level defaults, holding costs, reorder cost defaults, lead-time defaults

Import/export: CSV for sales, inventory counts, product list

Reports: monthly consumption, ABC classification (A/B/C by value or consumption)

Suggested React components:

InventoryTable — sortable, server-side paging / infinite scroll for large data

SKUCard — small card for each product with color-coded status

DemandChart — line chart (use Recharts or Chart.js) for daily demand and moving average

BoundsEditorModal — let user override computed min/max/safety stock per SKU

UX rules:

Allow manual override and keep audit trail.

Show both computed and overridden values, and indicate last recompute date.

10 — Example Python snippet (ETL + compute safety stock)

(This is illustrative pseudo-code; adapt to production.)

import pandas as pd
import numpy as np
from pymongo import MongoClient
from datetime import timedelta

def compute_bounds_for_sku(sku, db, window_days=90, service_level=0.95):
    sales_cursor = db.sales.find({"sku": sku, "sale_date": {"$gte": ... }})
    df = pd.DataFrame(list(sales_cursor))
    # roll up to daily demand
    df['date'] = pd.to_datetime(df['sale_date']).dt.date
    daily = df.groupby('date')['quantity'].sum().reindex(pd.date_range(start_date, end_date), fill_value=0)
    avg_daily = daily.mean()
    std_daily = daily.std(ddof=0)
    lead_times = [ (po['received_date'] - po['ordered_date']).days for po in db.purchase_orders.find({"sku":sku}) if po.get('received_date')]
    lead_mean = np.mean(lead_times) if lead_times else default_lead_time
    lead_var = np.var(lead_times) if len(lead_times)>1 else 0.0
    # approximate sigma during lead time
    sigma_lt = np.sqrt(lead_mean * (std_daily**2) + (avg_daily**2) * lead_var)
    # z for service level (95% -> 1.645)
    z = {0.90:1.282, 0.95:1.645, 0.99:2.33}.get(service_level, 1.645)
    safety_stock = int(np.ceil(z * sigma_lt))
    reorder_point = int(np.ceil(avg_daily * lead_mean + safety_stock))
    # recommended order qty (round to multiple of min_order_qty)
    eoq = compute_eoq(...) # optional
    recommended_qty = max(min_order_qty, int(round(eoq / min_order_qty) * min_order_qty))

    doc = {
      "sku": sku,
      "avg_daily_demand": float(avg_daily),
      "stddev_daily_demand": float(std_daily),
      "lead_time_days": float(lead_mean),
      "safety_stock": safety_stock,
      "reorder_point": reorder_point,
      "recommended_order_qty": recommended_qty,
      "computed_at": datetime.utcnow()
    }
    db.inventory_bounds.update_one({"sku":sku}, {"$set":doc}, upsert=True)

11 — MongoDB aggregation examples

Daily demand series for SKU:

db.sales.aggregate([
  { $match: { sku: "SKU1234", sale_date: { $gte: ISODate("2024-09-01") } } },
  { $group: { _id: { $dateToString: { format: "%Y-%m-%d", date: "$sale_date" } }, qty: { $sum: "$quantity" } } },
  { $sort: { _id: 1 } }
])


Total sales by SKU last 90 days:

db.sales.aggregate([
  { $match: { sale_date: { $gte: new Date(Date.now() - 90*24*60*60*1000) } } },
  { $group: { _id: "$sku", qty: { $sum: "$quantity" } } },
  { $sort: { qty: -1 } }
])

12 — Docker & Deployment

Use Docker Compose for local dev with services: mongo, redis (optional), node-api, python-service, react (nginx), minio (optional).

Use multi-stage Dockerfiles for Node and Python to keep images small.

Example docker-compose.yml services:

mongo (with volume)

node-api (port 3001)

frontend (nginx serving built React)

python-service (port 8000)

scheduler (can be part of python-service)

For production: deploy to Kubernetes (recommended if scaling), or Docker swarm / single VM + systemd + nginx reverse proxy. Use managed MongoDB Atlas if you prefer.

13 — Testing, validation & backtesting

Unit tests for each calculator (safety stock, ROP, EOQ).

Integration tests for ETL pipelines (small dataset).

Backtesting: simulate operations using historical sales + reorder policy; compute realized service level and stockouts. Iterate parameters (window lengths, service level) until desired tradeoffs met.

User acceptance tests: inventory clerk should be able to confirm and override suggestions.

14 — Monitoring & alerts

Track metrics: number of SKUs below reorder point, daily stockouts, PO lead-time averages, ETL job durations, failed jobs.

Alerting: when inventory.on_hand <= reorder_point create an alert document and email/push notification.

Logs: centralize (ELK or simpler file + Grafana Loki).

15 — Security & Data governance

Use HTTPS & JWT for API.

Role-based access for inventory actions.

Audit logs for adjustments/overrides.

Backups: daily/weekly snapshots of MongoDB.

Data retention: keep raw sales for at least 1-3 years (depending on business).

16 — Performance & big-data considerations

For very large sales history, store cold data in Parquet in object storage and run analytic jobs on that (Spark / Dask) — but you asked to keep MongoDB, so:

Keep raw transactional data in Mongo but create periodic summarized collections (daily_sales_by_sku) to significantly reduce compute.

Use aggregation pipelines to precompute and store daily/hourly rollups.

Consider time-series collections (MongoDB v5+).

17 — UX & business workflows

Make recompute scheduled (nightly) and manual button for immediate recompute.

Allow per-SKU configuration (service level, lead time, min order qty).

Show reason and inputs used for each computed bound (so users trust numbers).

Provide bulk download (CSV) of recommended orders for procurement.

18 — Suggested milestone timeline (approx)

(Assume small team; adjust to your resources.)

Week 1: Requirements, data sampling, schema design, basic MERN scaffolding.

Week 2: Implement Mongo collections, Node API skeleton, React auth + product CRUD.

Week 3: Python ETL prototype (single-SKU compute functions), Dockerize services.

Week 4: Aggregation endpoints, daily rollup collection, basic UI inventory table.

Week 5: Full bounds computation (batch), write to inventory_bounds, UI to display bounds, manual override.

Week 6: Alerts & notifications, backtesting & parameter tuning, testing.

Week 7: Performance tuning, indexing, sample deployment with Docker Compose.

Week 8: Documentation, final QA, handover.

19 — Deliverables checklist

 Data model & MongoDB schema (collections + indexes)

 Node/Express API with auth and inventory endpoints

 Python data service for ETL + bounds computation (containerized)

 React frontend with dashboard, SKU page, alerts, and overrides

 Docker Compose for local dev + production Dockerfiles

 Scheduling (cron/APScheduler) for nightly recompute jobs

 Backtesting scripts and test reports

 Monitoring & basic alerting

20 — Risks & mitigations

Bad/insufficient sales history → let system fall back to heuristics (average of category, safety factor) and mark estimates as low-confidence.

Intermittent demand → use Croston or classify SKU as intermittent and use different policy.

Supplier lead-time variability → track lead time distribution and include in sigma_LT formula.

Large data volumes → pre-aggregate daily rollups, or offload to a data-lake.

21 — Next steps & immediate implementation plan (what to code first)

Set up a small MongoDB dev instance and seed sample data (products + last 180 days sales).

Build minimal Node API with product and sales endpoints.

Implement Python compute_bounds_for_sku function and test on sample SKUs.

Create a React page that shows inventory_bounds values for a SKU.

Automate the daily job and expose a UI button to trigger recompute.

If you want, I can now:

generate the MongoDB schema + sample seed scripts for products + sales (JS/JSON),

produce the Python FastAPI microservice skeleton with the compute_bounds_for_sku implementation and Dockerfile,

scaffold the Express API and React components (basic pages) and Docker Compose file.